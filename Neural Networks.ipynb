{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#multiclass situation with mutually exclusive classes --> Softmax Function\n",
    "#1 Output note per class (dummy variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import cleaned data set\n",
    "df = pd.read_csv('cleaned_data/Cleaned Data.csv', index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Revenue</th>\n",
       "      <th>Revenue Growth</th>\n",
       "      <th>Cost of Revenue</th>\n",
       "      <th>Gross Profit</th>\n",
       "      <th>R&amp;D Expenses</th>\n",
       "      <th>SG&amp;A Expense</th>\n",
       "      <th>Operating Expenses</th>\n",
       "      <th>Operating Income</th>\n",
       "      <th>Interest Expense</th>\n",
       "      <th>Earnings before Tax</th>\n",
       "      <th>...</th>\n",
       "      <th>Consumer Cyclical</th>\n",
       "      <th>Consumer Defensive</th>\n",
       "      <th>Energy</th>\n",
       "      <th>Financial Services</th>\n",
       "      <th>Healthcare</th>\n",
       "      <th>Industrials</th>\n",
       "      <th>Real Estate</th>\n",
       "      <th>Technology</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>Signal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.734148e+09</td>\n",
       "      <td>1.1737</td>\n",
       "      <td>2.805625e+09</td>\n",
       "      <td>9.285226e+08</td>\n",
       "      <td>1.083303e+08</td>\n",
       "      <td>3.441414e+08</td>\n",
       "      <td>7.939267e+08</td>\n",
       "      <td>1.345959e+08</td>\n",
       "      <td>1.214869e+07</td>\n",
       "      <td>1.753823e+08</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.790960e+10</td>\n",
       "      <td>0.0076</td>\n",
       "      <td>1.153980e+10</td>\n",
       "      <td>6.369800e+09</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.474300e+09</td>\n",
       "      <td>3.412400e+09</td>\n",
       "      <td>2.957400e+09</td>\n",
       "      <td>3.024000e+08</td>\n",
       "      <td>2.707700e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Buy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.727000e+09</td>\n",
       "      <td>0.0214</td>\n",
       "      <td>3.523600e+09</td>\n",
       "      <td>2.203400e+09</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.480500e+09</td>\n",
       "      <td>1.598700e+09</td>\n",
       "      <td>6.047000e+08</td>\n",
       "      <td>6.040000e+07</td>\n",
       "      <td>4.669000e+08</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Buy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.972400e+10</td>\n",
       "      <td>0.0083</td>\n",
       "      <td>1.304100e+10</td>\n",
       "      <td>6.683000e+09</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.709000e+09</td>\n",
       "      <td>4.162000e+09</td>\n",
       "      <td>2.521000e+09</td>\n",
       "      <td>2.840000e+08</td>\n",
       "      <td>2.382000e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Buy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8.268000e+09</td>\n",
       "      <td>0.0268</td>\n",
       "      <td>5.297000e+09</td>\n",
       "      <td>2.971000e+09</td>\n",
       "      <td>1.220000e+08</td>\n",
       "      <td>1.505000e+09</td>\n",
       "      <td>1.704000e+09</td>\n",
       "      <td>1.267000e+09</td>\n",
       "      <td>1.220000e+08</td>\n",
       "      <td>1.240000e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Buy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11575</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.572500e+07</td>\n",
       "      <td>5.269000e+06</td>\n",
       "      <td>2.099400e+07</td>\n",
       "      <td>-2.099400e+07</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-2.113800e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Buy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11576</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.755251e+06</td>\n",
       "      <td>3.755251e+06</td>\n",
       "      <td>-3.755251e+06</td>\n",
       "      <td>1.105849e+07</td>\n",
       "      <td>-1.482451e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11577</th>\n",
       "      <td>5.488438e+07</td>\n",
       "      <td>0.2210</td>\n",
       "      <td>3.659379e+07</td>\n",
       "      <td>1.829059e+07</td>\n",
       "      <td>1.652633e+06</td>\n",
       "      <td>7.020320e+06</td>\n",
       "      <td>8.672953e+06</td>\n",
       "      <td>9.617636e+06</td>\n",
       "      <td>1.239170e+06</td>\n",
       "      <td>8.416324e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11578</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.031715e+07</td>\n",
       "      <td>4.521349e+06</td>\n",
       "      <td>1.664863e+07</td>\n",
       "      <td>-1.664863e+07</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.664769e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11579</th>\n",
       "      <td>5.301900e+07</td>\n",
       "      <td>0.0243</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.301900e+07</td>\n",
       "      <td>5.668400e+07</td>\n",
       "      <td>2.945700e+07</td>\n",
       "      <td>8.614600e+07</td>\n",
       "      <td>-3.312700e+07</td>\n",
       "      <td>1.660000e+05</td>\n",
       "      <td>-3.438500e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Buy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11579 rows × 231 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Revenue  Revenue Growth  Cost of Revenue  Gross Profit  \\\n",
       "1      3.734148e+09          1.1737     2.805625e+09  9.285226e+08   \n",
       "2      1.790960e+10          0.0076     1.153980e+10  6.369800e+09   \n",
       "3      5.727000e+09          0.0214     3.523600e+09  2.203400e+09   \n",
       "4      1.972400e+10          0.0083     1.304100e+10  6.683000e+09   \n",
       "5      8.268000e+09          0.0268     5.297000e+09  2.971000e+09   \n",
       "...             ...             ...              ...           ...   \n",
       "11575  0.000000e+00          0.0000     0.000000e+00  0.000000e+00   \n",
       "11576  0.000000e+00          0.0000     0.000000e+00  0.000000e+00   \n",
       "11577  5.488438e+07          0.2210     3.659379e+07  1.829059e+07   \n",
       "11578  0.000000e+00          0.0000     0.000000e+00  0.000000e+00   \n",
       "11579  5.301900e+07          0.0243     0.000000e+00  5.301900e+07   \n",
       "\n",
       "       R&D Expenses  SG&A Expense  Operating Expenses  Operating Income  \\\n",
       "1      1.083303e+08  3.441414e+08        7.939267e+08      1.345959e+08   \n",
       "2      0.000000e+00  3.474300e+09        3.412400e+09      2.957400e+09   \n",
       "3      0.000000e+00  1.480500e+09        1.598700e+09      6.047000e+08   \n",
       "4      0.000000e+00  3.709000e+09        4.162000e+09      2.521000e+09   \n",
       "5      1.220000e+08  1.505000e+09        1.704000e+09      1.267000e+09   \n",
       "...             ...           ...                 ...               ...   \n",
       "11575  1.572500e+07  5.269000e+06        2.099400e+07     -2.099400e+07   \n",
       "11576  0.000000e+00  3.755251e+06        3.755251e+06     -3.755251e+06   \n",
       "11577  1.652633e+06  7.020320e+06        8.672953e+06      9.617636e+06   \n",
       "11578  1.031715e+07  4.521349e+06        1.664863e+07     -1.664863e+07   \n",
       "11579  5.668400e+07  2.945700e+07        8.614600e+07     -3.312700e+07   \n",
       "\n",
       "       Interest Expense  Earnings before Tax  ...  Consumer Cyclical  \\\n",
       "1          1.214869e+07         1.753823e+08  ...                  0   \n",
       "2          3.024000e+08         2.707700e+09  ...                  0   \n",
       "3          6.040000e+07         4.669000e+08  ...                  0   \n",
       "4          2.840000e+08         2.382000e+09  ...                  0   \n",
       "5          1.220000e+08         1.240000e+09  ...                  0   \n",
       "...                 ...                  ...  ...                ...   \n",
       "11575      0.000000e+00        -2.113800e+07  ...                  0   \n",
       "11576      1.105849e+07        -1.482451e+07  ...                  0   \n",
       "11577      1.239170e+06         8.416324e+06  ...                  0   \n",
       "11578      0.000000e+00        -1.664769e+07  ...                  0   \n",
       "11579      1.660000e+05        -3.438500e+07  ...                  0   \n",
       "\n",
       "       Consumer Defensive  Energy  Financial Services  Healthcare  \\\n",
       "1                       1       0                   0           0   \n",
       "2                       1       0                   0           0   \n",
       "3                       1       0                   0           0   \n",
       "4                       1       0                   0           0   \n",
       "5                       1       0                   0           0   \n",
       "...                   ...     ...                 ...         ...   \n",
       "11575                   0       0                   0           1   \n",
       "11576                   0       0                   0           0   \n",
       "11577                   0       0                   0           0   \n",
       "11578                   0       0                   0           0   \n",
       "11579                   0       0                   0           1   \n",
       "\n",
       "       Industrials  Real Estate  Technology  Utilities  Signal  \n",
       "1                0            0           0          0    Sell  \n",
       "2                0            0           0          0     Buy  \n",
       "3                0            0           0          0     Buy  \n",
       "4                0            0           0          0     Buy  \n",
       "5                0            0           0          0     Buy  \n",
       "...            ...          ...         ...        ...     ...  \n",
       "11575            0            0           0          0     Buy  \n",
       "11576            0            1           0          0    Sell  \n",
       "11577            0            0           0          0    Sell  \n",
       "11578            1            0           0          0    Sell  \n",
       "11579            0            0           0          0     Buy  \n",
       "\n",
       "[11579 rows x 231 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Arrange response variable with dummy variable\n",
    "X = df.drop('Signal', axis=1)\n",
    "y = pd.get_dummies(df['Signal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Buy</th>\n",
       "      <th>Hold</th>\n",
       "      <th>Sell</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Buy  Hold  Sell\n",
       "1    0     0     1\n",
       "2    1     0     0\n",
       "3    1     0     0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#inspecting if transition worked for response variable\n",
    "y.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale our data to avoid issues (X_scaled = X_std * (max - min) + min)\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating an instance\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "#adjusting scaler only based on the training set (without test values to prevent data leakage)\n",
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform the transformation\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8105, 230)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import functions to create a neural network model based on keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up a empty sequential model\n",
    "model = Sequential()\n",
    "\n",
    "#adding dense layers (=regular densely-connected NN layer)\n",
    "#rule of thumb: Create as many NN as features for first layer\n",
    "model.add(Dense(230, activation='relu'))\n",
    "\n",
    "#dropout layer to prevent overfitting\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "#repeat process, but reduce amount of neurons for each step by half\n",
    "model.add(Dense(115, activation='relu'))\n",
    "model.add(Dropout(0.2))        \n",
    "          \n",
    "model.add(Dense(57, activation='relu'))\n",
    "model.add(Dropout(0.2))           \n",
    "          \n",
    "\n",
    "#1 Output neuron per class\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "#optimize a multi-class classification problem\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "32/32 [==============================] - 3s 9ms/step - loss: 0.9850 - accuracy: 0.4504\n",
      "Epoch 2/100\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.8883 - accuracy: 0.5179\n",
      "Epoch 3/100\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.8799 - accuracy: 0.5256\n",
      "Epoch 4/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.8832 - accuracy: 0.5179\n",
      "Epoch 5/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.8915 - accuracy: 0.5248\n",
      "Epoch 6/100\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.8746 - accuracy: 0.5271\n",
      "Epoch 7/100\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.8716 - accuracy: 0.5285\n",
      "Epoch 8/100\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.8792 - accuracy: 0.5256\n",
      "Epoch 9/100\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.8686 - accuracy: 0.5300\n",
      "Epoch 10/100\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.8807 - accuracy: 0.5202\n",
      "Epoch 11/100\n",
      "32/32 [==============================] - 1s 16ms/step - loss: 0.8720 - accuracy: 0.5332\n",
      "Epoch 12/100\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.8712 - accuracy: 0.5399\n",
      "Epoch 13/100\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.8724 - accuracy: 0.5447\n",
      "Epoch 14/100\n",
      "32/32 [==============================] - 1s 16ms/step - loss: 0.8762 - accuracy: 0.5302\n",
      "Epoch 15/100\n",
      "32/32 [==============================] - 1s 16ms/step - loss: 0.8716 - accuracy: 0.5442\n",
      "Epoch 16/100\n",
      "32/32 [==============================] - 1s 16ms/step - loss: 0.8642 - accuracy: 0.5505\n",
      "Epoch 17/100\n",
      "32/32 [==============================] - 1s 16ms/step - loss: 0.8730 - accuracy: 0.5367\n",
      "Epoch 18/100\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.8690 - accuracy: 0.5416\n",
      "Epoch 19/100\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.8685 - accuracy: 0.5473\n",
      "Epoch 20/100\n",
      "32/32 [==============================] - 1s 16ms/step - loss: 0.8624 - accuracy: 0.5417\n",
      "Epoch 21/100\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.8639 - accuracy: 0.5565 0s - loss: 0.8598 - accuracy\n",
      "Epoch 22/100\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.8617 - accuracy: 0.5456\n",
      "Epoch 23/100\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.8751 - accuracy: 0.5399\n",
      "Epoch 24/100\n",
      "32/32 [==============================] - 1s 16ms/step - loss: 0.8769 - accuracy: 0.5349\n",
      "Epoch 25/100\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.8635 - accuracy: 0.5336 0s - loss: 0.8619 - accuracy: \n",
      "Epoch 26/100\n",
      "32/32 [==============================] - 1s 16ms/step - loss: 0.8499 - accuracy: 0.5473 0s - loss: 0.8459 - accuracy: \n",
      "Epoch 27/100\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.8659 - accuracy: 0.5405\n",
      "Epoch 28/100\n",
      "32/32 [==============================] - 1s 16ms/step - loss: 0.8712 - accuracy: 0.5440\n",
      "Epoch 29/100\n",
      "32/32 [==============================] - 1s 16ms/step - loss: 0.8609 - accuracy: 0.5572\n",
      "Epoch 30/100\n",
      "32/32 [==============================] - 1s 16ms/step - loss: 0.8721 - accuracy: 0.5466\n",
      "Epoch 31/100\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.8689 - accuracy: 0.5470\n",
      "Epoch 32/100\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.8690 - accuracy: 0.5465\n",
      "Epoch 33/100\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.8603 - accuracy: 0.5463\n",
      "Epoch 34/100\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.8561 - accuracy: 0.5493\n",
      "Epoch 35/100\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.8625 - accuracy: 0.5444\n",
      "Epoch 36/100\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.8677 - accuracy: 0.5526\n",
      "Epoch 37/100\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.8526 - accuracy: 0.5467\n",
      "Epoch 38/100\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.8629 - accuracy: 0.5492\n",
      "Epoch 39/100\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.8650 - accuracy: 0.5541\n",
      "Epoch 40/100\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.8517 - accuracy: 0.5517\n",
      "Epoch 41/100\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.8556 - accuracy: 0.5612 0s - loss: 0.8532 - accuracy: \n",
      "Epoch 42/100\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.8612 - accuracy: 0.5474\n",
      "Epoch 43/100\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.8486 - accuracy: 0.5615\n",
      "Epoch 44/100\n",
      "32/32 [==============================] - 1s 16ms/step - loss: 0.8619 - accuracy: 0.5550\n",
      "Epoch 45/100\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.8526 - accuracy: 0.5508\n",
      "Epoch 46/100\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.8754 - accuracy: 0.5464\n",
      "Epoch 47/100\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.8543 - accuracy: 0.5596\n",
      "Epoch 48/100\n",
      "32/32 [==============================] - 1s 16ms/step - loss: 0.8465 - accuracy: 0.5589\n",
      "Epoch 49/100\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.8597 - accuracy: 0.5536\n",
      "Epoch 50/100\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.8525 - accuracy: 0.5612\n",
      "Epoch 51/100\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.8545 - accuracy: 0.5561\n",
      "Epoch 52/100\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.8555 - accuracy: 0.5643\n",
      "Epoch 53/100\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.8524 - accuracy: 0.5573 0s - loss: 0.8346 \n",
      "Epoch 54/100\n",
      "32/32 [==============================] - 1s 16ms/step - loss: 0.8491 - accuracy: 0.5582\n",
      "Epoch 55/100\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.8508 - accuracy: 0.5595\n",
      "Epoch 56/100\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.8610 - accuracy: 0.5650\n",
      "Epoch 57/100\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.8532 - accuracy: 0.5603\n",
      "Epoch 58/100\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.8433 - accuracy: 0.5632\n",
      "Epoch 59/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.8548 - accuracy: 0.5595\n",
      "Epoch 60/100\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.8611 - accuracy: 0.5527\n",
      "Epoch 61/100\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.8536 - accuracy: 0.5479\n",
      "Epoch 62/100\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.8597 - accuracy: 0.5557\n",
      "Epoch 63/100\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.8533 - accuracy: 0.5543\n",
      "Epoch 64/100\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.8641 - accuracy: 0.5672\n",
      "Epoch 65/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.8504 - accuracy: 0.5653\n",
      "Epoch 66/100\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.8443 - accuracy: 0.5675\n",
      "Epoch 67/100\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.8617 - accuracy: 0.5513\n",
      "Epoch 68/100\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.8535 - accuracy: 0.5634\n",
      "Epoch 69/100\n",
      "32/32 [==============================] - 0s 15ms/step - loss: 0.8542 - accuracy: 0.5605\n",
      "Epoch 70/100\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.8512 - accuracy: 0.5716\n",
      "Epoch 71/100\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.8542 - accuracy: 0.5661\n",
      "Epoch 72/100\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.8543 - accuracy: 0.5598\n",
      "Epoch 73/100\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.8351 - accuracy: 0.5768\n",
      "Epoch 74/100\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.8501 - accuracy: 0.5636\n",
      "Epoch 75/100\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.8469 - accuracy: 0.5654\n",
      "Epoch 76/100\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.8474 - accuracy: 0.5609\n",
      "Epoch 77/100\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.8504 - accuracy: 0.5617\n",
      "Epoch 78/100\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.8523 - accuracy: 0.5634\n",
      "Epoch 79/100\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.8453 - accuracy: 0.5707\n",
      "Epoch 80/100\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.8428 - accuracy: 0.5705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/100\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.8449 - accuracy: 0.5775\n",
      "Epoch 82/100\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.8438 - accuracy: 0.5678\n",
      "Epoch 83/100\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.8558 - accuracy: 0.5621\n",
      "Epoch 84/100\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.8459 - accuracy: 0.5648\n",
      "Epoch 85/100\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.8473 - accuracy: 0.5681\n",
      "Epoch 86/100\n",
      "32/32 [==============================] - 0s 15ms/step - loss: 0.8494 - accuracy: 0.5666\n",
      "Epoch 87/100\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.8333 - accuracy: 0.5743\n",
      "Epoch 88/100\n",
      "32/32 [==============================] - 0s 15ms/step - loss: 0.8474 - accuracy: 0.5668\n",
      "Epoch 89/100\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.8379 - accuracy: 0.5609\n",
      "Epoch 90/100\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.8432 - accuracy: 0.5692\n",
      "Epoch 91/100\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.8383 - accuracy: 0.5710\n",
      "Epoch 92/100\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.8400 - accuracy: 0.5743\n",
      "Epoch 93/100\n",
      "32/32 [==============================] - 0s 15ms/step - loss: 0.8347 - accuracy: 0.5785\n",
      "Epoch 94/100\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.8486 - accuracy: 0.5675\n",
      "Epoch 95/100\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.8357 - accuracy: 0.5724\n",
      "Epoch 96/100\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.8301 - accuracy: 0.5828\n",
      "Epoch 97/100\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.8437 - accuracy: 0.5746\n",
      "Epoch 98/100\n",
      "32/32 [==============================] - 1s 16ms/step - loss: 0.8535 - accuracy: 0.5694\n",
      "Epoch 99/100\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.8255 - accuracy: 0.5839\n",
      "Epoch 100/100\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.8348 - accuracy: 0.5691\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x19cd66917c0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit the model to our training date, \n",
    "#Our model will go trough the training data 100 times\n",
    "model.fit(x=X_train, y=y_train, epochs=100, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x19cd7c84580>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotting training history of our algorithm\n",
    "loss_df = pd.DataFrame(model.history.history)\n",
    "loss_df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8379701375961304, 0.5734731554985046]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#analysing performance on training data\n",
    "model.evaluate(X_train,y_train,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8833410739898682, 0.5518134832382202]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#analysing performance on test data\n",
    "model.evaluate(X_test,y_test,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving model\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Christian Rauhut\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3469</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3470</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3471</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3472</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3473</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3474 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0\n",
       "0     2\n",
       "1     2\n",
       "2     0\n",
       "3     2\n",
       "4     0\n",
       "...  ..\n",
       "3469  2\n",
       "3470  2\n",
       "3471  2\n",
       "3472  2\n",
       "3473  0\n",
       "\n",
       "[3474 rows x 1 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "predictions = model.predict_classes(X_test)\n",
    "pd.DataFrame(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6158     Sell\n",
       "5623     Sell\n",
       "3789      Buy\n",
       "457      Sell\n",
       "161      Sell\n",
       "         ... \n",
       "148      Sell\n",
       "11277     Buy\n",
       "9952      Buy\n",
       "6840      Buy\n",
       "8468     Sell\n",
       "Length: 3474, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = y_test.idxmax(axis=1)\n",
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to numbers for y_true\n",
    "SignalFac = []\n",
    "\n",
    "for string in y_true:\n",
    "    if string == 'Sell':\n",
    "        SignalFac.append(2)\n",
    "    elif string == 'Hold':\n",
    "        SignalFac.append(1)    \n",
    "    else:\n",
    "        SignalFac.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.24      0.32      1404\n",
      "           1       0.00      0.00      0.00       224\n",
      "           2       0.56      0.86      0.68      1846\n",
      "\n",
      "    accuracy                           0.55      3474\n",
      "   macro avg       0.36      0.37      0.33      3474\n",
      "weighted avg       0.50      0.55      0.49      3474\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(SignalFac,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We see F1 Score for predicting a Sell is the highest followed by the buy prediction\n",
    "#However, our model has some trouble to predict the hold signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sell    6153\n",
       "Buy     4681\n",
       "Hold     745\n",
       "Name: Signal, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Signal'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5313930391225494"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking if our model learned something\n",
    "6153/len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We see the accuracy of our model is better than the default guess on sell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 332    0 1072]\n",
      " [  59    0  165]\n",
      " [ 261    0 1585]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(SignalFac,predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
