{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Discriminant Analysis\n",
    "\n",
    "todo:\n",
    "- factorize signal\n",
    "- splits:\n",
    "    - split in training and test split\n",
    "    - split for Stratified-k-Fold Cross Validation\n",
    "- Feed model with:\n",
    "    - training set\n",
    "    - standardized training set\n",
    "    - balanced training set\n",
    "    - balanced standardized training set\n",
    "- checking the performance on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Revenue            3.73415e+09\n",
       "Revenue Growth          1.1737\n",
       "Cost of Revenue    2.80563e+09\n",
       "Gross Profit       9.28523e+08\n",
       "R&D Expenses        1.0833e+08\n",
       "                      ...     \n",
       "Industrials                  0\n",
       "Real Estate                  0\n",
       "Technology                   0\n",
       "Utilities                    0\n",
       "Signal                    Sell\n",
       "Name: 1, Length: 231, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import cleaned data frame\n",
    "df_cleaned = pd.read_csv('cleaned_data/Cleaned Data.csv', index_col=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factorize signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code by Christian\n",
    "SignalFac = []\n",
    "\n",
    "for string in df_cleaned['Signal']:\n",
    "    if string == 'Sell':\n",
    "        SignalFac.append(0)\n",
    "    elif string == 'Hold':\n",
    "        SignalFac.append(1)    \n",
    "    else:\n",
    "        SignalFac.append(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned['SignalFac'] = SignalFac\n",
    "df_cleaned.drop('Signal', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_cleaned.drop('SignalFac',axis=1)\n",
    "y = df_cleaned['SignalFac']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Split data in training and test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get training and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=0, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Setup for 5-fold CV on training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create k-Fold CV\n",
    "kFold = StratifiedKFold(n_splits = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed LDA with training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create LDA object and run classifier\n",
    "lda = LDA(solver=\"lsqr\")\n",
    "lda = lda.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.5492\n",
      "error-rate: 0.4508\n"
     ]
    }
   ],
   "source": [
    "# performance on training set\n",
    "print('score: {0:.4f}'.format(lda.score(X_train, y_train)))\n",
    "print('error-rate: {0:.4f}'.format(1-lda.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score test set: 0.5440\n"
     ]
    }
   ],
   "source": [
    "# performance on test set\n",
    "y_pred = lda.predict(X_test)\n",
    "print('score test set: {0:.4f}'.format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.87      0.67      1846\n",
      "           1       0.05      0.00      0.01       224\n",
      "           2       0.47      0.18      0.26      1404\n",
      "\n",
      "    accuracy                           0.53      3474\n",
      "   macro avg       0.36      0.35      0.31      3474\n",
      "weighted avg       0.49      0.53      0.46      3474\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix: \n",
      " [[1611   11  224]\n",
      " [ 175    1   48]\n",
      " [1148   10  246]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print('Confusion matrix: \\n', \n",
    "      metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed LDA with standardized training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize features\n",
    "# Apply StandardScaler on continuous columns only (our data is continuous)\n",
    "stdsc = StandardScaler()\n",
    "X_train_std = stdsc.fit_transform(X_train) # fit & transform\n",
    "X_test_std = stdsc.transform(X_test) # ONLY transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create LDA object and run classifier on standardized features\n",
    "lda_std = LDA(solver=\"lsqr\")\n",
    "lda_std = lda_std.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.5314\n",
      "error-rate: 0.4686\n"
     ]
    }
   ],
   "source": [
    "# performance on standardized training set\n",
    "print('score: {0:.4f}'.format(lda.score(X_train_std, y_train)))\n",
    "print('error-rate: {0:.4f}'.format(1-lda.score(X_train_std, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score standardized test set: 0.5314\n"
     ]
    }
   ],
   "source": [
    "# performance on standardized test set\n",
    "y_pred_std = lda.predict(X_test_std)\n",
    "print('score standardized test set: {0:.4f}'.format(accuracy_score(y_test, y_pred_std)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed LDA with balanaced training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11579, 230) (6153,) (745,) (4681,)\n"
     ]
    }
   ],
   "source": [
    "# check how the data looks like\n",
    "print(X.shape, y[y==0].shape, y[y==1].shape, y[y==2].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18459,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# upsampling for balanced data set\n",
    "X_upsampled, y_upsampled = resample(X[y==1], y[y==1],\n",
    "                                   replace = True,\n",
    "                                   n_samples = X[y==0].shape[0],\n",
    "                                   random_state=1)\n",
    "X_upsampled_2, y_upsampled_2 = resample(X[y==2], y[y==2],\n",
    "                                   replace = True,\n",
    "                                   n_samples = X[y==0].shape[0],\n",
    "                                   random_state=1)\n",
    "\n",
    "# combining the different classifications together\n",
    "X_bal = np.vstack((X[y==0], X_upsampled, X_upsampled_2))\n",
    "y_bal = np.hstack((y[y==0], y_upsampled, y_upsampled_2))\n",
    "\n",
    "# check how large the data is\n",
    "y_bal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the balanced data set \n",
    "X_train_bal, X_test_bal, y_train_bal, y_test_bal = \\\n",
    "    train_test_split(X_bal, y_bal, \n",
    "                     test_size = 0.3, \n",
    "                     random_state = 0, \n",
    "                     stratify = y_bal)\n",
    "\n",
    "# standardize the balanced data set\n",
    "X_train_bal_std = stdsc.fit_transform(X_train_bal)\n",
    "X_test_bal_std =stdsc.transform(X_test_bal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.46      0.46      1846\n",
      "           1       0.47      0.53      0.50      1846\n",
      "           2       0.41      0.35      0.38      1846\n",
      "\n",
      "    accuracy                           0.45      5538\n",
      "   macro avg       0.44      0.45      0.44      5538\n",
      "weighted avg       0.44      0.45      0.44      5538\n",
      "\n",
      "[[854 508 484]\n",
      " [407 971 468]\n",
      " [601 594 651]]\n",
      "Test score : 0.45\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "model = LDA(solver=\"lsqr\")\n",
    "model.fit(X_train_bal_std, y_train_bal)\n",
    "\n",
    "y_pred_bal = model.predict(X_test_bal_std)\n",
    "print(metrics.classification_report(y_test_bal, y_pred_bal))\n",
    "print(metrics.confusion_matrix(y_test_bal, y_pred_bal))\n",
    "print(\"Test score : {:.2f}\".format(model.score(X_test_bal_std, y_test_bal)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
